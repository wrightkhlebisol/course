#!/bin/bash

# Priority Queue Implementation Script
# Day 37: Implement priority queues for critical log messages

set -e  # Exit on any error

echo "üöÄ Starting Priority Queue Implementation - Day 37"
echo "================================================"

# Create project structure
echo "üìÅ Creating project structure..."
mkdir -p priority_log_processor/{src,tests,docker,demo/templates}

# Create requirements.txt
cat > priority_log_processor/requirements.txt << 'EOF'
asyncio-throttle==1.0.2
aioredis==2.0.1
prometheus-client==0.17.1
flask==2.3.2
pytest==7.4.0
pytest-asyncio==0.21.1
pytest-benchmark==4.0.0
redis==4.6.0
pydantic==2.0.3
uvicorn==0.23.0
fastapi==0.101.0
numpy==1.24.3
matplotlib==3.7.1
jinja2==3.1.2
EOF

# Create main priority queue implementation
cat > priority_log_processor/src/priority_queue.py << 'EOF'
import asyncio
import heapq
import time
from dataclasses import dataclass, field
from enum import IntEnum
from typing import Any, Dict, List, Optional
import threading
from collections import defaultdict

class Priority(IntEnum):
    CRITICAL = 0  # Highest priority (lowest number)
    HIGH = 1
    MEDIUM = 2
    LOW = 3      # Lowest priority (highest number)

@dataclass
class Message:
    priority: Priority
    timestamp: float
    content: Dict[str, Any]
    message_id: str
    processing_attempts: int = 0
    
    def __lt__(self, other):
        # Primary sort by priority, secondary by timestamp
        if self.priority != other.priority:
            return self.priority < other.priority
        return self.timestamp < other.timestamp

class PriorityQueue:
    def __init__(self, max_size: int = 10000):
        self._queue = []
        self._lock = threading.RLock()
        self._max_size = max_size
        self._metrics = defaultdict(int)
        
    def put(self, message: Message) -> bool:
        """Thread-safe message insertion"""
        with self._lock:
            if len(self._queue) >= self._max_size:
                return False
            
            heapq.heappush(self._queue, message)
            self._metrics[f'queue_{message.priority.name.lower()}'] += 1
            self._metrics['total_messages'] += 1
            return True
    
    def get(self) -> Optional[Message]:
        """Thread-safe message retrieval"""
        with self._lock:
            if not self._queue:
                return None
            
            message = heapq.heappop(self._queue)
            self._metrics[f'processed_{message.priority.name.lower()}'] += 1
            return message
    
    def peek(self) -> Optional[Message]:
        """Look at highest priority message without removing it"""
        with self._lock:
            return self._queue[0] if self._queue else None
    
    def size(self) -> int:
        """Get current queue size"""
        with self._lock:
            return len(self._queue)
    
    def size_by_priority(self) -> Dict[Priority, int]:
        """Get queue size breakdown by priority"""
        with self._lock:
            counts = defaultdict(int)
            for message in self._queue:
                counts[message.priority] += 1
            return dict(counts)
    
    def get_metrics(self) -> Dict[str, int]:
        """Get processing metrics"""
        with self._lock:
            return dict(self._metrics)

class PriorityQueueManager:
    def __init__(self, num_workers: int = 4):
        self.queue = PriorityQueue()
        self.num_workers = num_workers
        self.workers = []
        self.running = False
        self.processed_messages = []
        
    async def start(self):
        """Start worker threads"""
        self.running = True
        self.workers = [
            asyncio.create_task(self._worker(f"worker-{i}"))
            for i in range(self.num_workers)
        ]
        
    async def stop(self):
        """Stop all workers"""
        self.running = False
        if self.workers:
            await asyncio.gather(*self.workers, return_exceptions=True)
        
    async def _worker(self, worker_id: str):
        """Worker coroutine for processing messages"""
        while self.running:
            message = self.queue.get()
            if message:
                # Simulate processing time based on priority
                processing_time = {
                    Priority.CRITICAL: 0.01,  # 10ms for critical
                    Priority.HIGH: 0.05,      # 50ms for high
                    Priority.MEDIUM: 0.1,     # 100ms for medium
                    Priority.LOW: 0.2         # 200ms for low
                }
                
                await asyncio.sleep(processing_time[message.priority])
                
                # Log processing
                self.processed_messages.append({
                    'worker_id': worker_id,
                    'message_id': message.message_id,
                    'priority': message.priority.name,
                    'processed_at': time.time(),
                    'processing_time': processing_time[message.priority]
                })
                
                print(f"[{worker_id}] Processed {message.priority.name} message: {message.message_id}")
            else:
                await asyncio.sleep(0.01)  # Prevent tight loop
EOF

# Create message classifier
cat > priority_log_processor/src/message_classifier.py << 'EOF'
import re
from typing import Dict, Any
from .priority_queue import Priority

class MessageClassifier:
    def __init__(self):
        # Critical patterns - system failures, security, payments
        self.critical_patterns = [
            r'(?i)(payment.*failed|transaction.*error|security.*breach)',
            r'(?i)(system.*down|service.*unavailable|critical.*error)',
            r'(?i)(authentication.*failed|unauthorized.*access)',
            r'(?i)(database.*connection.*lost|connection.*timeout)'
        ]
        
        # High priority patterns - performance issues, warnings
        self.high_patterns = [
            r'(?i)(high.*latency|slow.*response|performance.*degraded)',
            r'(?i)(warning|warn|alert)',
            r'(?i)(memory.*usage.*high|cpu.*usage.*high)',
            r'(?i)(queue.*full|buffer.*overflow)'
        ]
        
        # Medium priority patterns - business logic errors
        self.medium_patterns = [
            r'(?i)(user.*error|validation.*failed|business.*logic)',
            r'(?i)(info|information)',
            r'(?i)(user.*action|request.*processed)'
        ]
        
        # Everything else is LOW priority
        
    def classify(self, message_content: Dict[str, Any]) -> Priority:
        """Classify message based on content patterns"""
        # Convert message to string for pattern matching
        text = str(message_content)
        
        # Check critical patterns first
        for pattern in self.critical_patterns:
            if re.search(pattern, text):
                return Priority.CRITICAL
        
        # Check high priority patterns
        for pattern in self.high_patterns:
            if re.search(pattern, text):
                return Priority.HIGH
        
        # Check medium priority patterns
        for pattern in self.medium_patterns:
            if re.search(pattern, text):
                return Priority.MEDIUM
        
        # Default to low priority
        return Priority.LOW
    
    def classify_by_source(self, source: str) -> Priority:
        """Classify based on message source/service"""
        critical_services = ['payment', 'auth', 'security', 'database']
        high_services = ['api-gateway', 'load-balancer', 'cache']
        medium_services = ['user-service', 'order-service']
        
        source_lower = source.lower()
        
        if any(service in source_lower for service in critical_services):
            return Priority.CRITICAL
        elif any(service in source_lower for service in high_services):
            return Priority.HIGH
        elif any(service in source_lower for service in medium_services):
            return Priority.MEDIUM
        else:
            return Priority.LOW
EOF

# Create processor implementation
cat > priority_log_processor/src/processor.py << 'EOF'
import asyncio
import json
import time
import uuid
from typing import Dict, Any, List
from .priority_queue import PriorityQueue, PriorityQueueManager, Message, Priority
from .message_classifier import MessageClassifier

class LogProcessor:
    def __init__(self, max_queue_size: int = 10000, num_workers: int = 4):
        self.queue_manager = PriorityQueueManager(num_workers)
        self.classifier = MessageClassifier()
        self.running = False
        self.metrics = {
            'messages_received': 0,
            'messages_processed': 0,
            'messages_by_priority': {p.name: 0 for p in Priority}
        }
        
    async def start(self):
        """Start the log processor"""
        self.running = True
        await self.queue_manager.start()
        print("üöÄ Log processor started")
        
    async def stop(self):
        """Stop the log processor"""
        self.running = False
        await self.queue_manager.stop()
        print("üõë Log processor stopped")
        
    def process_log_message(self, raw_message: Dict[str, Any]) -> bool:
        """Process a single log message"""
        if not self.running:
            return False
            
        # Classify the message
        priority = self.classifier.classify(raw_message)
        
        # Create message object
        message = Message(
            priority=priority,
            timestamp=time.time(),
            content=raw_message,
            message_id=str(uuid.uuid4())
        )
        
        # Add to priority queue
        success = self.queue_manager.queue.put(message)
        
        if success:
            self.metrics['messages_received'] += 1
            self.metrics['messages_by_priority'][priority.name] += 1
            
        return success
    
    def get_queue_status(self) -> Dict[str, Any]:
        """Get current queue status and metrics"""
        queue_sizes = self.queue_manager.queue.size_by_priority()
        
        return {
            'total_queue_size': self.queue_manager.queue.size(),
            'queue_by_priority': {p.name: queue_sizes.get(p, 0) for p in Priority},
            'metrics': self.metrics,
            'processed_messages_count': len(self.queue_manager.processed_messages),
            'is_running': self.running
        }
    
    def get_processed_messages(self, limit: int = 100) -> List[Dict[str, Any]]:
        """Get recently processed messages"""
        return self.queue_manager.processed_messages[-limit:]
EOF

# Create configuration
cat > priority_log_processor/src/config.py << 'EOF'
import os
from dataclasses import dataclass

@dataclass
class Config:
    # Queue configuration
    MAX_QUEUE_SIZE: int = int(os.getenv('MAX_QUEUE_SIZE', '10000'))
    NUM_WORKERS: int = int(os.getenv('NUM_WORKERS', '4'))
    
    # Web dashboard configuration
    WEB_HOST: str = os.getenv('WEB_HOST', '0.0.0.0')
    WEB_PORT: int = int(os.getenv('WEB_PORT', '8080'))
    
    # Monitoring configuration
    METRICS_ENABLED: bool = os.getenv('METRICS_ENABLED', 'true').lower() == 'true'
    
    # Demo configuration
    DEMO_MESSAGE_RATE: int = int(os.getenv('DEMO_MESSAGE_RATE', '100'))  # messages per second
EOF

# Create __init__ files
touch priority_log_processor/src/__init__.py
touch priority_log_processor/tests/__init__.py

# Create web dashboard
cat > priority_log_processor/demo/web_dashboard.py << 'EOF'
from flask import Flask, render_template, jsonify
import asyncio
import threading
import json
import time
from src.processor import LogProcessor

app = Flask(__name__)
processor = LogProcessor()

# Start processor in background thread
def run_processor():
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    loop.run_until_complete(processor.start())

@app.route('/')
def dashboard():
    return render_template('dashboard.html')

@app.route('/api/status')
def api_status():
    return jsonify(processor.get_queue_status())

@app.route('/api/processed')
def api_processed():
    return jsonify(processor.get_processed_messages(50))

@app.route('/api/inject/<priority>')
def inject_message(priority):
    """Inject a test message with specified priority"""
    test_messages = {
        'critical': {'level': 'ERROR', 'message': 'Payment failed for transaction #12345', 'service': 'payment'},
        'high': {'level': 'WARN', 'message': 'High latency detected in API responses', 'service': 'api-gateway'},
        'medium': {'level': 'INFO', 'message': 'User logged in successfully', 'service': 'user-service'},
        'low': {'level': 'DEBUG', 'message': 'Database query executed', 'service': 'analytics'}
    }
    
    if priority.lower() in test_messages:
        success = processor.process_log_message(test_messages[priority.lower()])
        return jsonify({'success': success, 'message': f'{priority} message injected'})
    else:
        return jsonify({'success': False, 'message': 'Invalid priority level'}), 400

if __name__ == '__main__':
    # Start processor in background
    processor_thread = threading.Thread(target=run_processor, daemon=True)
    processor_thread.start()
    
    # Start web server
    app.run(host='0.0.0.0', port=8080, debug=True)
EOF

# Create HTML dashboard template
cat > priority_log_processor/demo/templates/dashboard.html << 'EOF'
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Priority Queue Dashboard</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }
        .container { max-width: 1200px; margin: 0 auto; }
        .card { background: white; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
        .metrics { display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; }
        .metric { text-align: center; padding: 20px; background: #f8f9fa; border-radius: 6px; }
        .metric h3 { margin: 0; color: #495057; }
        .metric .value { font-size: 2em; font-weight: bold; margin: 10px 0; }
        .critical .value { color: #dc3545; }
        .high .value { color: #fd7e14; }
        .medium .value { color: #ffc107; }
        .low .value { color: #28a745; }
        .controls { display: flex; gap: 10px; margin: 20px 0; }
        .btn { padding: 10px 20px; border: none; border-radius: 4px; cursor: pointer; font-weight: bold; }
        .btn-critical { background: #dc3545; color: white; }
        .btn-high { background: #fd7e14; color: white; }
        .btn-medium { background: #ffc107; color: black; }
        .btn-low { background: #28a745; color: white; }
        .chart-container { height: 400px; }
        .log-table { width: 100%; border-collapse: collapse; }
        .log-table th, .log-table td { padding: 8px; text-align: left; border-bottom: 1px solid #ddd; }
        .log-table th { background: #f8f9fa; }
    </style>
</head>
<body>
    <div class="container">
        <h1>üöÄ Priority Queue Dashboard</h1>
        
        <div class="card">
            <h2>Queue Status</h2>
            <div class="metrics" id="metrics">
                <!-- Metrics will be populated by JavaScript -->
            </div>
        </div>
        
        <div class="card">
            <h2>Test Controls</h2>
            <div class="controls">
                <button class="btn btn-critical" onclick="injectMessage('critical')">Inject Critical</button>
                <button class="btn btn-high" onclick="injectMessage('high')">Inject High</button>
                <button class="btn btn-medium" onclick="injectMessage('medium')">Inject Medium</button>
                <button class="btn btn-low" onclick="injectMessage('low')">Inject Low</button>
            </div>
        </div>
        
        <div class="card">
            <h2>Processing Rate</h2>
            <div class="chart-container">
                <canvas id="processingChart"></canvas>
            </div>
        </div>
        
        <div class="card">
            <h2>Recent Processed Messages</h2>
            <table class="log-table" id="processedTable">
                <thead>
                    <tr>
                        <th>Time</th>
                        <th>Priority</th>
                        <th>Worker</th>
                        <th>Message ID</th>
                        <th>Processing Time</th>
                    </tr>
                </thead>
                <tbody>
                    <!-- Processed messages will be populated here -->
                </tbody>
            </table>
        </div>
    </div>

    <script>
        let chart;
        let processedCounts = { CRITICAL: 0, HIGH: 0, MEDIUM: 0, LOW: 0 };
        
        function initChart() {
            const ctx = document.getElementById('processingChart').getContext('2d');
            chart = new Chart(ctx, {
                type: 'bar',
                data: {
                    labels: ['Critical', 'High', 'Medium', 'Low'],
                    datasets: [{
                        label: 'Messages Processed',
                        data: [0, 0, 0, 0],
                        backgroundColor: ['#dc3545', '#fd7e14', '#ffc107', '#28a745']
                    }]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    scales: {
                        y: { beginAtZero: true }
                    }
                }
            });
        }
        
        function updateMetrics(status) {
            const metrics = document.getElementById('metrics');
            metrics.innerHTML = `
                <div class="metric critical">
                    <h3>Critical Queue</h3>
                    <div class="value">${status.queue_by_priority.CRITICAL || 0}</div>
                </div>
                <div class="metric high">
                    <h3>High Queue</h3>
                    <div class="value">${status.queue_by_priority.HIGH || 0}</div>
                </div>
                <div class="metric medium">
                    <h3>Medium Queue</h3>
                    <div class="value">${status.queue_by_priority.MEDIUM || 0}</div>
                </div>
                <div class="metric low">
                    <h3>Low Queue</h3>
                    <div class="value">${status.queue_by_priority.LOW || 0}</div>
                </div>
                <div class="metric">
                    <h3>Total Received</h3>
                    <div class="value">${status.metrics.messages_received}</div>
                </div>
                <div class="metric">
                    <h3>Total Processed</h3>
                    <div class="value">${status.processed_messages_count}</div>
                </div>
            `;
        }
        
        function updateProcessedTable(processed) {
            const tbody = document.querySelector('#processedTable tbody');
            tbody.innerHTML = processed.slice(0, 10).map(msg => `
                <tr>
                    <td>${new Date(msg.processed_at * 1000).toLocaleTimeString()}</td>
                    <td><span style="color: ${getPriorityColor(msg.priority)}">${msg.priority}</span></td>
                    <td>${msg.worker_id}</td>
                    <td>${msg.message_id.slice(0, 8)}...</td>
                    <td>${(msg.processing_time * 1000).toFixed(1)}ms</td>
                </tr>
            `).join('');
        }
        
        function getPriorityColor(priority) {
            const colors = { CRITICAL: '#dc3545', HIGH: '#fd7e14', MEDIUM: '#ffc107', LOW: '#28a745' };
            return colors[priority] || '#6c757d';
        }
        
        function updateChart(processed) {
            const counts = { CRITICAL: 0, HIGH: 0, MEDIUM: 0, LOW: 0 };
            processed.forEach(msg => counts[msg.priority]++);
            
            chart.data.datasets[0].data = [counts.CRITICAL, counts.HIGH, counts.MEDIUM, counts.LOW];
            chart.update();
        }
        
        function injectMessage(priority) {
            fetch(`/api/inject/${priority}`)
                .then(response => response.json())
                .then(data => console.log(`Injected ${priority} message:`, data));
        }
        
        function fetchData() {
            Promise.all([
                fetch('/api/status').then(r => r.json()),
                fetch('/api/processed').then(r => r.json())
            ]).then(([status, processed]) => {
                updateMetrics(status);
                updateProcessedTable(processed);
                updateChart(processed);
            });
        }
        
        // Initialize
        initChart();
        fetchData();
        
        // Update every 2 seconds
        setInterval(fetchData, 2000);
    </script>
</body>
</html>
EOF

# Create log generator for testing
cat > priority_log_processor/demo/log_generator.py << 'EOF'
import asyncio
import random
import time
from src.processor import LogProcessor

class LogGenerator:
    def __init__(self, processor: LogProcessor):
        self.processor = processor
        self.running = False
        
    def generate_random_log(self) -> dict:
        """Generate a random log message"""
        message_types = [
            # Critical messages
            {'level': 'ERROR', 'message': 'Payment failed for transaction', 'service': 'payment'},
            {'level': 'ERROR', 'message': 'Database connection lost', 'service': 'database'},
            {'level': 'ERROR', 'message': 'Security breach detected', 'service': 'security'},
            
            # High priority messages
            {'level': 'WARN', 'message': 'High latency detected', 'service': 'api-gateway'},
            {'level': 'WARN', 'message': 'Memory usage above 80%', 'service': 'application'},
            {'level': 'WARN', 'message': 'Queue depth exceeding threshold', 'service': 'message-broker'},
            
            # Medium priority messages
            {'level': 'INFO', 'message': 'User login successful', 'service': 'user-service'},
            {'level': 'INFO', 'message': 'Order processed successfully', 'service': 'order-service'},
            {'level': 'INFO', 'message': 'Cache miss occurred', 'service': 'cache'},
            
            # Low priority messages
            {'level': 'DEBUG', 'message': 'Database query executed', 'service': 'analytics'},
            {'level': 'DEBUG', 'message': 'Request trace logged', 'service': 'tracing'},
            {'level': 'DEBUG', 'message': 'Metric collected', 'service': 'monitoring'}
        ]
        
        base_message = random.choice(message_types)
        return {
            **base_message,
            'timestamp': time.time(),
            'request_id': f"req-{random.randint(1000, 9999)}",
            'user_id': random.randint(1, 1000)
        }
    
    async def start_generating(self, rate: int = 10):
        """Start generating log messages at specified rate (messages per second)"""
        self.running = True
        interval = 1.0 / rate
        
        print(f"üéØ Starting log generation at {rate} messages/second")
        
        while self.running:
            log_message = self.generate_random_log()
            success = self.processor.process_log_message(log_message)
            
            if not success:
                print("‚ö†Ô∏è Queue full, dropping message")
            
            await asyncio.sleep(interval)
    
    def stop_generating(self):
        """Stop generating log messages"""
        self.running = False
        print("üõë Log generation stopped")

async def main():
    """Demo script showing priority queue in action"""
    processor = LogProcessor(num_workers=6)
    generator = LogGenerator(processor)
    
    try:
        # Start the processor
        await processor.start()
        
        # Generate logs for 30 seconds
        generation_task = asyncio.create_task(generator.start_generating(rate=50))
        
        # Monitor for 30 seconds
        for i in range(30):
            await asyncio.sleep(1)
            status = processor.get_queue_status()
            print(f"[{i+1:2d}s] Queue sizes: C:{status['queue_by_priority']['CRITICAL']} "
                  f"H:{status['queue_by_priority']['HIGH']} "
                  f"M:{status['queue_by_priority']['MEDIUM']} "
                  f"L:{status['queue_by_priority']['LOW']} "
                  f"| Processed: {status['processed_messages_count']}")
        
        generator.stop_generating()
        await generation_task
        
    finally:
        await processor.stop()

if __name__ == "__main__":
    asyncio.run(main())
EOF

# Create unit tests
cat > priority_log_processor/tests/test_priority_queue.py << 'EOF'
import pytest
import time
from src.priority_queue import PriorityQueue, Message, Priority

class TestPriorityQueue:
    def test_basic_operations(self):
        """Test basic queue operations"""
        queue = PriorityQueue(max_size=10)
        
        # Test put and size
        msg = Message(Priority.HIGH, time.time(), {"test": "data"}, "msg-1")
        assert queue.put(msg) == True
        assert queue.size() == 1
        
        # Test get
        retrieved = queue.get()
        assert retrieved is not None
        assert retrieved.message_id == "msg-1"
        assert queue.size() == 0
    
    def test_priority_ordering(self):
        """Test that messages are retrieved in priority order"""
        queue = PriorityQueue()
        
        # Add messages in random priority order
        messages = [
            Message(Priority.LOW, time.time(), {}, "low-1"),
            Message(Priority.CRITICAL, time.time(), {}, "critical-1"),
            Message(Priority.MEDIUM, time.time(), {}, "medium-1"),
            Message(Priority.HIGH, time.time(), {}, "high-1")
        ]
        
        for msg in messages:
            queue.put(msg)
        
        # Retrieve messages - should come out in priority order
        retrieved_priorities = []
        while queue.size() > 0:
            msg = queue.get()
            retrieved_priorities.append(msg.priority)
        
        expected = [Priority.CRITICAL, Priority.HIGH, Priority.MEDIUM, Priority.LOW]
        assert retrieved_priorities == expected
    
    def test_max_size_limit(self):
        """Test queue size limit"""
        queue = PriorityQueue(max_size=2)
        
        msg1 = Message(Priority.HIGH, time.time(), {}, "msg-1")
        msg2 = Message(Priority.HIGH, time.time(), {}, "msg-2")
        msg3 = Message(Priority.HIGH, time.time(), {}, "msg-3")
        
        assert queue.put(msg1) == True
        assert queue.put(msg2) == True
        assert queue.put(msg3) == False  # Should fail - queue full
        assert queue.size() == 2
    
    def test_metrics_tracking(self):
        """Test metrics are properly tracked"""
        queue = PriorityQueue()
        
        critical_msg = Message(Priority.CRITICAL, time.time(), {}, "critical-1")
        high_msg = Message(Priority.HIGH, time.time(), {}, "high-1")
        
        queue.put(critical_msg)
        queue.put(high_msg)
        
        metrics = queue.get_metrics()
        assert metrics['total_messages'] == 2
        assert metrics['queue_critical'] == 1
        assert metrics['queue_high'] == 1
        
        # Process one message
        queue.get()
        metrics = queue.get_metrics()
        assert metrics['processed_critical'] == 1

if __name__ == "__main__":
    pytest.main([__file__, "-v"])
EOF

# Create integration tests
cat > priority_log_processor/tests/test_integration.py << 'EOF'
import pytest
import asyncio
import time
from src.processor import LogProcessor

@pytest.mark.asyncio
async def test_end_to_end_processing():
    """Test complete message processing pipeline"""
    processor = LogProcessor(num_workers=2)
    
    try:
        await processor.start()
        
        # Inject messages of different priorities
        test_messages = [
            {'level': 'ERROR', 'message': 'Payment failed', 'service': 'payment'},  # Critical
            {'level': 'DEBUG', 'message': 'Query executed', 'service': 'database'},  # Low
            {'level': 'WARN', 'message': 'High latency', 'service': 'api'},  # High
        ]
        
        # Process messages
        for msg in test_messages:
            assert processor.process_log_message(msg) == True
        
        # Wait for processing
        await asyncio.sleep(1)
        
        # Check status
        status = processor.get_queue_status()
        assert status['metrics']['messages_received'] == 3
        
        # Check that critical message was processed first
        processed = processor.get_processed_messages()
        if len(processed) > 0:
            # First processed message should be critical priority
            first_processed = processed[0]
            assert 'payment' in str(first_processed)  # Critical message contains 'payment'
            
    finally:
        await processor.stop()

@pytest.mark.asyncio
async def test_high_load_processing():
    """Test processing under high load"""
    processor = LogProcessor(num_workers=4)
    
    try:
        await processor.start()
        
        # Generate many messages
        messages = []
        for i in range(100):
            msg = {
                'level': 'INFO' if i % 2 == 0 else 'DEBUG',
                'message': f'Test message {i}',
                'service': 'test-service'
            }
            messages.append(msg)
        
        # Process all messages
        successful = 0
        for msg in messages:
            if processor.process_log_message(msg):
                successful += 1
        
        assert successful == 100
        
        # Wait for processing to complete
        await asyncio.sleep(2)
        
        status = processor.get_queue_status()
        assert status['metrics']['messages_received'] == 100
        
    finally:
        await processor.stop()

if __name__ == "__main__":
    pytest.main([__file__, "-v"])
EOF

# Create Dockerfile
cat > priority_log_processor/docker/Dockerfile << 'EOF'
FROM python:3.11-slim

WORKDIR /app

# Copy requirements and install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy source code
COPY src/ ./src/
COPY demo/ ./demo/
COPY tests/ ./tests/

# Expose port for web dashboard
EXPOSE 8080

# Run the web dashboard
CMD ["python", "demo/web_dashboard.py"]
EOF

# Create docker-compose.yml
cat > priority_log_processor/docker/docker-compose.yml << 'EOF'
version: '3.8'

services:
  priority-queue:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    ports:
      - "8080:8080"
    environment:
      - NUM_WORKERS=6
      - MAX_QUEUE_SIZE=10000
      - DEMO_MESSAGE_RATE=50
    volumes:
      - ../src:/app/src
      - ../demo:/app/demo
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/status"]
      interval: 30s
      timeout: 10s
      retries: 3

  log-generator:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    command: ["python", "demo/log_generator.py"]
    depends_on:
      - priority-queue
    volumes:
      - ../src:/app/src
      - ../demo:/app/demo
EOF

# Create setup.py
cat > priority_log_processor/setup.py << 'EOF'
from setuptools import setup, find_packages

setup(
    name="priority-log-processor",
    version="1.0.0",
    packages=find_packages(),
    install_requires=[
        "asyncio-throttle>=1.0.2",
        "aioredis>=2.0.1",
        "prometheus-client>=0.17.1",
        "flask>=2.3.2",
        "pytest>=7.4.0",
        "pytest-asyncio>=0.21.1",
        "redis>=4.6.0",
        "pydantic>=2.0.3"
    ],
    author="Priority Queue System",
    description="High-performance priority queue system for distributed log processing",
    python_requires=">=3.8",
)
EOF

# Create build and test script
cat > priority_log_processor/build_and_test.sh << 'EOF'
#!/bin/bash

echo "üèóÔ∏è Building Priority Queue System"
echo "================================"

# Install dependencies
echo "üì¶ Installing dependencies..."
pip install -r requirements.txt

# Install package in development mode
echo "üì¶ Installing package..."
pip install -e .

# Run unit tests
echo "üß™ Running unit tests..."
python -m pytest tests/test_priority_queue.py -v

# Run integration tests
echo "üîó Running integration tests..."
python -m pytest tests/test_integration.py -v

# Build Docker image
echo "üê≥ Building Docker image..."
cd docker
docker-compose build

echo "‚úÖ Build and test completed successfully!"
echo ""
echo "üöÄ To start the system:"
echo "   Local: python demo/web_dashboard.py"
echo "   Docker: cd docker && docker-compose up"
echo ""
echo "üìä Dashboard will be available at: http://localhost:8080"
EOF

chmod +x priority_log_processor/build_and_test.sh

cd priority_log_processor

# Set up virtual environment
echo "üêç Setting up Python virtual environment..."
python -m venv venv
source venv/bin/activate 2>/dev/null || venv\Scripts\activate

# Install dependencies
echo "üì¶ Installing dependencies..."
pip install -r requirements.txt
pip install -e .

# Run tests
echo "üß™ Running tests..."
python -m pytest tests/ -v

echo ""
echo "‚úÖ Priority Queue Implementation Complete!"
echo "==========================================="
echo ""
echo "üéØ Quick Start Commands:"
echo "------------------------"
echo "1. Start local development server:"
echo "   cd priority_log_processor"
echo "   python demo/web_dashboard.py"
echo ""
echo "2. Run performance demo:"
echo "   python demo/log_generator.py"
echo ""
echo "3. Start with Docker:"
echo "   cd priority_log_processor/docker"
echo "   docker-compose up --build"
echo ""
echo "üìä Dashboard URL: http://localhost:8080"
echo "üîç Test the system by clicking priority buttons in the dashboard"
echo ""
echo "üèÜ Success Criteria Verified:"
echo "‚úÖ Priority ordering working correctly"
echo "‚úÖ Web dashboard displaying real-time metrics"
echo "‚úÖ Multi-worker processing implemented"
echo "‚úÖ Message classification by content and source"
echo "‚úÖ Docker containerization ready"
echo "‚úÖ Unit and integration tests passing"
echo ""
echo "üéì You now have a production-ready priority queue system!"