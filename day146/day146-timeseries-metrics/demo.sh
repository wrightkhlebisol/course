#!/bin/bash
set -e

echo "üé¨ Day 146 Demo: Time Series Metrics System"
echo "============================================"
echo ""

# Activate venv
source venv/bin/activate

# Check if TimescaleDB is running
echo "1Ô∏è‚É£  Checking TimescaleDB connection..."
python -c "
import psycopg2
try:
    conn = psycopg2.connect(
        host='localhost',
        port=5432,
        database='metrics',
        user='postgres',
        password='password'
    )
    conn.close()
    print('   ‚úÖ TimescaleDB connected')
except Exception as e:
    print('   ‚ùå TimescaleDB not available. Start with: docker-compose up -d timescaledb')
    exit(1)
"

# Setup schema
echo ""
echo "2Ô∏è‚É£  Setting up database schema..."
python -c "
from src.writers.timescale_writer import TimescaleWriter
writer = TimescaleWriter({
    'host': 'localhost',
    'port': 5432,
    'database': 'metrics',
    'user': 'postgres',
    'password': 'password'
})
writer.setup_schema()
writer.close()
print('   ‚úÖ Schema created')
"

# Generate and process logs
echo ""
echo "3Ô∏è‚É£  Generating and processing test logs..."
python -c "
import sys
import os
sys.path.insert(0, os.path.join(os.getcwd(), 'src'))
import asyncio
from main import MetricsPipeline

async def demo():
    pipeline = MetricsPipeline()
    pipeline.setup()
    print('   üîÑ Processing logs for 30 seconds...')
    await pipeline.process_logs(duration=30)
    pipeline.stop()
    print('   ‚úÖ Log processing complete')

asyncio.run(demo())
"

# Query metrics
echo ""
echo "4Ô∏è‚É£  Querying metrics from TimescaleDB..."
python -c "
import psycopg2
from psycopg2.extras import RealDictCursor

conn = psycopg2.connect(
    host='localhost',
    port=5432,
    database='metrics',
    user='postgres',
    password='password',
    cursor_factory=RealDictCursor
)
cur = conn.cursor()

# Response time metrics
cur.execute('''
    SELECT 
        service,
        COUNT(*) as count,
        AVG(response_time_ms) as avg_response_time,
        MIN(response_time_ms) as min_response_time,
        MAX(response_time_ms) as max_response_time
    FROM http_response
    GROUP BY service
    ORDER BY service;
''')

print('   üìä Response Time Metrics:')
for row in cur.fetchall():
    print(f\"      {row['service']}: {row['avg_response_time']:.2f}ms avg (min: {row['min_response_time']:.2f}, max: {row['max_response_time']:.2f}, count: {row['count']})\")

# Error rates
cur.execute('''
    SELECT 
        service,
        COUNT(*) as total,
        SUM(is_error) as errors,
        (SUM(is_error)::float / COUNT(*)::float * 100) as error_rate
    FROM http_status
    GROUP BY service
    ORDER BY service;
''')

print('   üö® Error Rate Metrics:')
for row in cur.fetchall():
    print(f\"      {row['service']}: {row['error_rate']:.2f}% ({row['errors']}/{row['total']})\")

conn.close()
print('   ‚úÖ Query complete')
"

echo ""
echo "5Ô∏è‚É£  Starting API and Dashboard..."
echo "   Run these commands in separate terminals:"
echo "   Terminal 1: uvicorn src.api.query_api:app --reload"
echo "   Terminal 2: cd src/dashboard && npm start"
echo ""
echo "   Then visit: http://localhost:3000"
echo ""
echo "‚úÖ Demo complete!"
