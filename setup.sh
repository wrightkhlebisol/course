#!/bin/bash

# Day 23: Log Partitioning Strategy Implementation Script
# 254-Day Hands-On System Design Series

set -e

echo "=== Day 23: Log Partitioning Strategy Setup ==="
echo "Building distributed log storage with intelligent partitioning..."

# Create project structure
echo "üìÅ Creating project structure..."
mkdir -p log_partitioning/{src,tests,config,data,logs,web}
cd log_partitioning

# Create main source files
echo "üìù Creating source files..."

# Partition Router Implementation
cat > src/partition_router.py << 'EOF'
import hashlib
import json
from datetime import datetime, timedelta
from typing import Dict, List, Any
import logging

class PartitionRouter:
    def __init__(self, strategy="source", nodes=None, time_window_hours=24):
        self.strategy = strategy
        self.nodes = nodes or ["node_1", "node_2", "node_3"]
        self.time_window_hours = time_window_hours
        self.partition_map = {}
        
    def route_log(self, log_entry: Dict[str, Any]) -> str:
        """Route log to appropriate partition based on strategy"""
        if self.strategy == "source":
            return self._route_by_source(log_entry)
        elif self.strategy == "time":
            return self._route_by_time(log_entry)
        else:
            raise ValueError(f"Unknown strategy: {self.strategy}")
    
    def _route_by_source(self, log_entry: Dict[str, Any]) -> str:
        source = log_entry.get("source", "unknown")
        hash_val = int(hashlib.md5(source.encode()).hexdigest(), 16)
        node_index = hash_val % len(self.nodes)
        return self.nodes[node_index]
    
    def _route_by_time(self, log_entry: Dict[str, Any]) -> str:
        timestamp = log_entry.get("timestamp", datetime.now().isoformat())
        dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
        
        # Time-based partitioning by hours
        hour_bucket = dt.hour // (24 // len(self.nodes))
        node_index = min(hour_bucket, len(self.nodes) - 1)
        return self.nodes[node_index]
    
    def get_query_partitions(self, query_filter: Dict[str, Any]) -> List[str]:
        """Determine which partitions to query based on filter"""
        if self.strategy == "source" and "source" in query_filter:
            # Only query partition containing this source
            dummy_log = {"source": query_filter["source"]}
            return [self._route_by_source(dummy_log)]
        elif self.strategy == "time" and "time_range" in query_filter:
            # Only query partitions in time range
            return self._get_time_partitions(query_filter["time_range"])
        else:
            # Query all partitions
            return self.nodes
    
    def _get_time_partitions(self, time_range: Dict[str, str]) -> List[str]:
        start = datetime.fromisoformat(time_range["start"])
        end = datetime.fromisoformat(time_range["end"])
        
        partitions = set()
        current = start
        while current <= end:
            dummy_log = {"timestamp": current.isoformat()}
            partitions.add(self._route_by_time(dummy_log))
            current += timedelta(hours=1)
        
        return list(partitions)
EOF

# Partition Manager Implementation
cat > src/partition_manager.py << 'EOF'
import os
import json
import threading
from typing import Dict, List, Any
from collections import defaultdict
import time

class PartitionManager:
    def __init__(self, data_dir="data"):
        self.data_dir = data_dir
        self.partitions = defaultdict(list)
        self.partition_stats = defaultdict(dict)
        self.lock = threading.Lock()
        self._ensure_data_dir()
    
    def _ensure_data_dir(self):
        os.makedirs(self.data_dir, exist_ok=True)
        for node in ["node_1", "node_2", "node_3"]:
            os.makedirs(f"{self.data_dir}/{node}", exist_ok=True)
    
    def store_log(self, partition: str, log_entry: Dict[str, Any]):
        """Store log entry in specified partition"""
        with self.lock:
            # Add to in-memory partition
            self.partitions[partition].append(log_entry)
            
            # Update partition stats
            self._update_partition_stats(partition, log_entry)
            
            # Persist to disk
            self._persist_log(partition, log_entry)
    
    def _persist_log(self, partition: str, log_entry: Dict[str, Any]):
        """Persist log entry to disk"""
        file_path = f"{self.data_dir}/{partition}/logs.jsonl"
        with open(file_path, "a") as f:
            f.write(json.dumps(log_entry) + "\n")
    
    def _update_partition_stats(self, partition: str, log_entry: Dict[str, Any]):
        """Update partition statistics"""
        stats = self.partition_stats[partition]
        stats["log_count"] = stats.get("log_count", 0) + 1
        stats["last_updated"] = time.time()
        
        # Track sources
        source = log_entry.get("source", "unknown")
        sources = stats.get("sources", set())
        sources.add(source)
        stats["sources"] = sources
    
    def query_partition(self, partition: str, filter_criteria: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Query logs from specific partition"""
        results = []
        
        with self.lock:
            for log in self.partitions[partition]:
                if self._matches_filter(log, filter_criteria):
                    results.append(log)
        
        return results
    
    def _matches_filter(self, log: Dict[str, Any], criteria: Dict[str, Any]) -> bool:
        """Check if log matches filter criteria"""
        for key, value in criteria.items():
            if key not in log:
                return False
            if key == "time_range":
                log_time = log.get("timestamp", "")
                if not (value["start"] <= log_time <= value["end"]):
                    return False
            elif log[key] != value:
                return False
        return True
    
    def get_partition_stats(self) -> Dict[str, Dict[str, Any]]:
        """Get statistics for all partitions"""
        stats = {}
        for partition, partition_stats in self.partition_stats.items():
            stats[partition] = {
                "log_count": partition_stats.get("log_count", 0),
                "sources": list(partition_stats.get("sources", set())),
                "last_updated": partition_stats.get("last_updated", 0)
            }
        return stats
EOF

# Query Optimizer Implementation
cat > src/query_optimizer.py << 'EOF'
import time
from typing import Dict, List, Any
from src.partition_router import PartitionRouter
from src.partition_manager import PartitionManager

class QueryOptimizer:
    def __init__(self, router: PartitionRouter, manager: PartitionManager):
        self.router = router
        self.manager = manager
        self.query_stats = []
    
    def execute_query(self, filter_criteria: Dict[str, Any]) -> Dict[str, Any]:
        """Execute optimized query across relevant partitions"""
        start_time = time.time()
        
        # Determine which partitions to query
        target_partitions = self.router.get_query_partitions(filter_criteria)
        
        # Query each relevant partition
        all_results = []
        for partition in target_partitions:
            partition_results = self.manager.query_partition(partition, filter_criteria)
            all_results.extend(partition_results)
        
        execution_time = time.time() - start_time
        
        # Record query statistics
        query_stat = {
            "filter": filter_criteria,
            "partitions_queried": target_partitions,
            "total_partitions": len(self.router.nodes),
            "results_count": len(all_results),
            "execution_time": execution_time,
            "partition_efficiency": len(target_partitions) / len(self.router.nodes)
        }
        self.query_stats.append(query_stat)
        
        return {
            "results": all_results,
            "stats": query_stat
        }
    
    def get_performance_comparison(self) -> Dict[str, Any]:
        """Generate performance comparison between optimized and brute-force"""
        if not self.query_stats:
            return {"message": "No queries executed yet"}
        
        latest_query = self.query_stats[-1]
        optimized_time = latest_query["execution_time"]
        
        # Simulate brute-force time (would query all partitions)
        brute_force_multiplier = len(self.router.nodes) / len(latest_query["partitions_queried"])
        estimated_brute_force_time = optimized_time * brute_force_multiplier
        
        improvement_factor = estimated_brute_force_time / optimized_time if optimized_time > 0 else 1
        
        return {
            "optimized_time": optimized_time,
            "estimated_brute_force_time": estimated_brute_force_time,
            "improvement_factor": improvement_factor,
            "partitions_pruned": len(self.router.nodes) - len(latest_query["partitions_queried"]),
            "efficiency_percentage": latest_query["partition_efficiency"] * 100
        }
EOF

# Main Application
cat > src/log_partitioning_system.py << 'EOF'
from datetime import datetime, timedelta
import random
import json
from src.partition_router import PartitionRouter
from src.partition_manager import PartitionManager
from src.query_optimizer import QueryOptimizer

class LogPartitioningSystem:
    def __init__(self, strategy="source"):
        self.router = PartitionRouter(strategy=strategy)
        self.manager = PartitionManager()
        self.optimizer = QueryOptimizer(self.router, self.manager)
        self.processed_logs = 0
    
    def ingest_log(self, log_entry):
        """Ingest a single log entry"""
        partition = self.router.route_log(log_entry)
        self.manager.store_log(partition, log_entry)
        self.processed_logs += 1
        return partition
    
    def generate_sample_logs(self, count=1000):
        """Generate sample logs for testing"""
        sources = ["web_server", "database", "auth_service", "api_gateway", "cache"]
        levels = ["INFO", "WARNING", "ERROR", "DEBUG"]
        
        logs = []
        base_time = datetime.now() - timedelta(hours=24)
        
        for i in range(count):
            log = {
                "id": f"log_{i:04d}",
                "source": random.choice(sources),
                "level": random.choice(levels),
                "message": f"Sample log message {i}",
                "timestamp": (base_time + timedelta(minutes=random.randint(0, 1440))).isoformat(),
                "user_id": f"user_{random.randint(1, 100)}"
            }
            logs.append(log)
        
        return logs
    
    def demo_partitioning(self):
        """Demonstrate partitioning system with sample data"""
        print("üöÄ Starting Log Partitioning Demo")
        
        # Generate and ingest sample logs
        print("üìä Generating sample logs...")
        sample_logs = self.generate_sample_logs(1000)
        
        print("üì• Ingesting logs...")
        for log in sample_logs:
            self.ingest_log(log)
        
        print(f"‚úÖ Processed {self.processed_logs} logs")
        
        # Show partition distribution
        stats = self.manager.get_partition_stats()
        print("\nüìà Partition Distribution:")
        for partition, stat in stats.items():
            print(f"  {partition}: {stat['log_count']} logs, Sources: {stat['sources']}")
        
        # Demo optimized queries
        print("\nüîç Testing Query Optimization:")
        
        # Query by source
        if self.router.strategy == "source":
            query_result = self.optimizer.execute_query({"source": "web_server"})
            print(f"  Source query: Found {len(query_result['results'])} web_server logs")
            print(f"  Queried {len(query_result['stats']['partitions_queried'])}/{len(self.router.nodes)} partitions")
        
        # Query by time range
        time_start = (datetime.now() - timedelta(hours=2)).isoformat()
        time_end = datetime.now().isoformat()
        time_query = self.optimizer.execute_query({
            "time_range": {"start": time_start, "end": time_end}
        })
        print(f"  Time query: Found {len(time_query['results'])} logs in last 2 hours")
        
        # Show performance comparison
        perf = self.optimizer.get_performance_comparison()
        print(f"\n‚ö° Performance Improvement:")
        print(f"  Improvement Factor: {perf['improvement_factor']:.1f}x faster")
        print(f"  Efficiency: {perf['efficiency_percentage']:.1f}%")
        
        return {
            "logs_processed": self.processed_logs,
            "partition_stats": stats,
            "performance": perf
        }

if __name__ == "__main__":
    # Demo both strategies
    print("=== SOURCE-BASED PARTITIONING ===")
    source_system = LogPartitioningSystem("source")
    source_results = source_system.demo_partitioning()
    
    print("\n=== TIME-BASED PARTITIONING ===")
    time_system = LogPartitioningSystem("time")
    time_results = time_system.demo_partitioning()
EOF

# Web Dashboard
cat > web/dashboard.html << 'EOF'
<!DOCTYPE html>
<html>
<head>
    <title>Log Partitioning Dashboard</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }
        .container { max-width: 1200px; margin: 0 auto; }
        .card { background: white; padding: 20px; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
        .metric { display: inline-block; margin: 10px 20px; text-align: center; }
        .metric-value { font-size: 2em; font-weight: bold; color: #4CAF50; }
        .metric-label { color: #666; }
        .partition { padding: 10px; margin: 5px; background: #e3f2fd; border-left: 4px solid #2196F3; }
        .chart { height: 200px; background: #f9f9f9; border: 1px solid #ddd; display: flex; align-items: end; padding: 10px; }
        .bar { background: #4CAF50; margin: 2px; color: white; text-align: center; display: flex; align-items: end; justify-content: center; min-width: 60px; }
    </style>
</head>
<body>
    <div class="container">
        <h1>üóÇÔ∏è Log Partitioning Dashboard</h1>
        
        <div class="card">
            <h2>System Overview</h2>
            <div class="metric">
                <div class="metric-value" id="totalLogs">0</div>
                <div class="metric-label">Total Logs</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="totalPartitions">3</div>
                <div class="metric-label">Active Partitions</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="queryImprovement">0x</div>
                <div class="metric-label">Query Improvement</div>
            </div>
        </div>

        <div class="card">
            <h2>Partition Distribution</h2>
            <div class="chart" id="partitionChart">
                <div class="bar" style="height: 60%">Node 1<br>340</div>
                <div class="bar" style="height: 80%">Node 2<br>450</div>
                <div class="bar" style="height: 40%">Node 3<br>210</div>
            </div>
        </div>

        <div class="card">
            <h2>Partition Details</h2>
            <div id="partitionDetails">
                <div class="partition">
                    <strong>node_1</strong> - 340 logs<br>
                    Sources: web_server, database<br>
                    Last Updated: 2 minutes ago
                </div>
                <div class="partition">
                    <strong>node_2</strong> - 450 logs<br>
                    Sources: auth_service, api_gateway<br>
                    Last Updated: 1 minute ago
                </div>
                <div class="partition">
                    <strong>node_3</strong> - 210 logs<br>
                    Sources: cache<br>
                    Last Updated: 30 seconds ago
                </div>
            </div>
        </div>

        <div class="card">
            <h2>Query Performance</h2>
            <p><strong>Last Query:</strong> source='web_server'</p>
            <p><strong>Partitions Queried:</strong> 1 of 3 (33% efficiency)</p>
            <p><strong>Execution Time:</strong> 0.045s (estimated 0.135s without partitioning)</p>
            <p><strong>Performance Gain:</strong> 3.0x faster</p>
        </div>
    </div>

    <script>
        // Simulate real-time updates
        function updateMetrics() {
            const totalLogs = Math.floor(Math.random() * 1000) + 500;
            document.getElementById('totalLogs').textContent = totalLogs;
            
            const improvement = (Math.random() * 5 + 2).toFixed(1);
            document.getElementById('queryImprovement').textContent = improvement + 'x';
        }

        setInterval(updateMetrics, 3000);
        updateMetrics();
    </script>
</body>
</html>
EOF

# Test files
echo "üß™ Creating test files..."

cat > tests/test_partition_router.py << 'EOF'
import unittest
from datetime import datetime
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.partition_router import PartitionRouter

class TestPartitionRouter(unittest.TestCase):
    
    def setUp(self):
        self.source_router = PartitionRouter(strategy="source")
        self.time_router = PartitionRouter(strategy="time")
    
    def test_source_routing_consistency(self):
        """Test that same source always routes to same partition"""
        log1 = {"source": "web_server", "timestamp": "2024-01-01T10:00:00"}
        log2 = {"source": "web_server", "timestamp": "2024-01-02T15:30:00"}
        
        partition1 = self.source_router.route_log(log1)
        partition2 = self.source_router.route_log(log2)
        
        self.assertEqual(partition1, partition2)
    
    def test_different_sources_distribution(self):
        """Test that different sources can map to different partitions"""
        sources = ["web_server", "database", "auth_service", "cache", "api_gateway"]
        partitions = set()
        
        for source in sources:
            log = {"source": source, "timestamp": "2024-01-01T10:00:00"}
            partition = self.source_router.route_log(log)
            partitions.add(partition)
        
        # Should have distribution across partitions
        self.assertGreater(len(partitions), 1)
    
    def test_time_routing_same_bucket(self):
        """Test that logs in same time bucket go to same partition"""
        log1 = {"source": "web_server", "timestamp": "2024-01-01T10:00:00"}
        log2 = {"source": "database", "timestamp": "2024-01-01T10:30:00"}
        
        partition1 = self.time_router.route_log(log1)
        partition2 = self.time_router.route_log(log2)
        
        self.assertEqual(partition1, partition2)
    
    def test_query_partition_pruning_source(self):
        """Test query optimization for source-based partitioning"""
        partitions = self.source_router.get_query_partitions({"source": "web_server"})
        
        # Should return only one partition for specific source
        self.assertEqual(len(partitions), 1)
    
    def test_query_partition_pruning_time(self):
        """Test query optimization for time-based partitioning"""
        time_filter = {
            "time_range": {
                "start": "2024-01-01T10:00:00",
                "end": "2024-01-01T12:00:00"
            }
        }
        partitions = self.time_router.get_query_partitions(time_filter)
        
        # Should return limited partitions for time range
        self.assertLessEqual(len(partitions), 3)

if __name__ == "__main__":
    unittest.main()
EOF

cat > tests/test_integration.py << 'EOF'
import unittest
import tempfile
import shutil
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.log_partitioning_system import LogPartitioningSystem

class TestIntegration(unittest.TestCase):
    
    def setUp(self):
        self.temp_dir = tempfile.mkdtemp()
        self.system = LogPartitioningSystem("source")
        self.system.manager.data_dir = self.temp_dir
        self.system.manager._ensure_data_dir()
    
    def tearDown(self):
        shutil.rmtree(self.temp_dir)
    
    def test_end_to_end_workflow(self):
        """Test complete workflow from ingestion to query"""
        # Generate sample logs
        logs = self.system.generate_sample_logs(100)
        
        # Ingest logs
        for log in logs:
            self.system.ingest_log(log)
        
        # Verify logs were distributed
        stats = self.system.manager.get_partition_stats()
        total_logs = sum(stat['log_count'] for stat in stats.values())
        self.assertEqual(total_logs, 100)
        
        # Test query optimization
        query_result = self.system.optimizer.execute_query({"source": "web_server"})
        
        # Should find some results and show efficiency
        self.assertGreater(len(query_result['results']), 0)
        self.assertLessEqual(len(query_result['stats']['partitions_queried']), 3)
    
    def test_performance_improvement(self):
        """Test that partitioning shows performance improvement"""
        # Generate and ingest logs
        logs = self.system.generate_sample_logs(500)
        for log in logs:
            self.system.ingest_log(log)
        
        # Execute query
        self.system.optimizer.execute_query({"source": "database"})
        
        # Check performance metrics
        perf = self.system.optimizer.get_performance_comparison()
        self.assertGreater(perf['improvement_factor'], 1.0)
        self.assertGreater(perf['efficiency_percentage'], 0)

if __name__ == "__main__":
    unittest.main()
EOF

# Configuration
cat > config/partitioning_config.json << 'EOF'
{
    "strategies": {
        "source": {
            "enabled": true,
            "hash_function": "md5",
            "nodes": ["node_1", "node_2", "node_3"]
        },
        "time": {
            "enabled": true,
            "window_hours": 8,
            "nodes": ["node_1", "node_2", "node_3"]
        }
    },
    "storage": {
        "data_directory": "data",
        "file_format": "jsonl",
        "compression": false
    },
    "performance": {
        "batch_size": 100,
        "query_timeout": 30,
        "max_results": 10000
    }
}
EOF

# Requirements file
cat > requirements.txt << 'EOF'
pytest==7.4.0
flask==2.3.2
requests==2.31.0
python-dateutil==2.8.2
EOF

# Docker setup
cat > Dockerfile << 'EOF'
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 5000

CMD ["python", "src/log_partitioning_system.py"]
EOF

cat > docker-compose.yml << 'EOF'
version: '3.8'

services:
  log-partitioning:
    build: .
    ports:
      - "5000:5000"
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    environment:
      - PARTITION_STRATEGY=source
      - NODE_COUNT=3
  
  web-dashboard:
    image: nginx:alpine
    ports:
      - "8080:80"
    volumes:
      - ./web:/usr/share/nginx/html
EOF

echo "üèóÔ∏è Building and testing system..."

# Install dependencies
echo "üì¶ Installing dependencies..."
pip install -r requirements.txt

# Run tests
echo "üß™ Running unit tests..."
python -m pytest tests/ -v

# Run integration demo
echo "üöÄ Running integration demo..."
python src/log_partitioning_system.py

echo "üåê Starting web dashboard..."
echo "Dashboard available at: http://localhost:8080"

# Build and test commands
echo ""
echo "=== BUILD AND VERIFY COMMANDS ==="
echo ""
echo "# Manual Testing Commands:"
echo "python src/log_partitioning_system.py  # Run demo"
echo "python -m pytest tests/ -v             # Run tests"
echo "python -c \"
from src.log_partitioning_system import LogPartitioningSystem
system = LogPartitioningSystem('source')
result = system.demo_partitioning()
print('‚úÖ Demo completed successfully')
print(f'Processed: {result[\"logs_processed\"]} logs')
print(f'Performance: {result[\"performance\"][\"improvement_factor\"]:.1f}x improvement')
\""
echo ""
echo "# Docker Commands:"
echo "docker-compose up -d                    # Start services"
echo "docker-compose logs log-partitioning    # View logs"
echo "docker-compose down                     # Stop services"
echo ""
echo "# Expected Output:"
echo "‚úÖ 1000 logs processed and partitioned"
echo "‚úÖ Query performance improvement of 2-10x"
echo "‚úÖ Web dashboard showing partition distribution"
echo "‚úÖ All tests passing"

echo ""
echo "üéâ Log Partitioning System Setup Complete!"
echo "üìä Check the dashboard at http://localhost:8080"
echo "üîç Test queries to see partitioning benefits"